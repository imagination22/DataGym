{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c361b5f-0ff7-4129-8c48-0da83a97f07f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2041 - Accepted Candidates From the Interviews\n",
    "### Table: Candidates\n",
    "\n",
    "| Column Name  | Type    |\n",
    "|--------------|---------|\n",
    "| candidate_id | int     |\n",
    "| name         | varchar |\n",
    "| years_of_exp | int     |\n",
    "| interview_id | int     |\n",
    "\n",
    "candidate_id is the primary key column for this table.  \n",
    "Each row of this table indicates the name of a candidate, their number of years of experience, and their interview ID.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Rounds\n",
    "\n",
    "| Column Name  | Type |\n",
    "|--------------|------|\n",
    "| interview_id | int  |\n",
    "| round_id     | int  |\n",
    "| score        | int  |\n",
    "\n",
    "(interview_id, round_id) is the primary key column for this table.  \n",
    "Each row of this table indicates the score of one round of an interview.\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Write an SQL query to report the IDs of the candidates who have at least two years of experience and the sum of the score of their interview rounds is strictly greater than 15.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 1:\n",
    "\n",
    "#### Input:\n",
    "\n",
    "##### Candidates table:\n",
    "\n",
    "| candidate_id | name    | years_of_exp | interview_id |\n",
    "|--------------|---------|--------------|--------------|\n",
    "| 11           | Atticus | 1            | 101          |\n",
    "| 9            | Ruben   | 6            | 104          |\n",
    "| 6            | Aliza   | 10           | 109          |\n",
    "| 8            | Alfredo | 0            | 107          |\n",
    "\n",
    "##### Rounds table:\n",
    "\n",
    "| interview_id | round_id | score |\n",
    "|--------------|----------|-------|\n",
    "| 109          | 3        | 4     |\n",
    "| 101          | 2        | 8     |\n",
    "| 109          | 4        | 1     |\n",
    "| 107          | 1        | 3     |\n",
    "| 104          | 3        | 6     |\n",
    "| 109          | 1        | 4     |\n",
    "| 104          | 4        | 7     |\n",
    "| 104          | 1        | 2     |\n",
    "| 109          | 2        | 1     |\n",
    "| 104          | 2        | 7     |\n",
    "| 107          | 2        | 3     |\n",
    "| 101          | 1        | 8     |\n",
    "\n",
    "---\n",
    "\n",
    "#### Output:\n",
    "\n",
    "| candidate_id |\n",
    "|--------------|\n",
    "| 9            |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "- Candidate 11: The total score is 16, and they have one year of experience. We do not include them in the result table because of their years of experience.  \n",
    "- Candidate 9: The total score is 22, and they have six years of experience. We include them in the result table.  \n",
    "- Candidate 6: The total score is 10, and they have ten years of experience. We do not include them in the result table because the score is not good enough.  \n",
    "- Candidate 8: The total score is 6, and they have zero years of experience. We do not include them in the result table because of their years of experience and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049bdd1b-7cde-416c-9d41-352e77f52039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define schemas\n",
    "candidates_schema = StructType([\n",
    "    StructField(\"candidate_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"years_of_exp\", IntegerType(), True),\n",
    "    StructField(\"interview_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "rounds_schema = StructType([\n",
    "    StructField(\"interview_id\", IntegerType(), True),\n",
    "    StructField(\"round_id\", IntegerType(), True),\n",
    "    StructField(\"score\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "candidates_data = [\n",
    "    (11, \"Atticus\", 1, 101),\n",
    "    (9, \"Ruben\", 6, 104),\n",
    "    (6, \"Aliza\", 10, 109),\n",
    "    (8, \"Alfredo\", 0, 107)\n",
    "]\n",
    "\n",
    "rounds_data = [\n",
    "    (109, 3, 4),\n",
    "    (101, 2, 8),\n",
    "    (109, 4, 1),\n",
    "    (107, 1, 3),\n",
    "    (104, 3, 6),\n",
    "    (109, 1, 4),\n",
    "    (104, 4, 7),\n",
    "    (104, 1, 2),\n",
    "    (109, 2, 1),\n",
    "    (104, 2, 7),\n",
    "    (107, 2, 3),\n",
    "    (101, 1, 8)\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "candidates_df = spark.createDataFrame(candidates_data, schema=candidates_schema)\n",
    "rounds_df = spark.createDataFrame(rounds_data, schema=rounds_schema)\n",
    "\n",
    "# Register temp views\n",
    "candidates_df.createOrReplaceTempView(\"Candidates\")\n",
    "rounds_df.createOrReplaceTempView(\"Rounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2230f9ad-2e9c-4a6c-adaf-cd1f216a5a0a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758686190246}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "c_df = candidates_df.selectExpr(\n",
    "    \"candidate_id as c_id\", \"name\", \"years_of_exp\", \"interview_id  as c_i_id\"\n",
    ")\n",
    "r_df = rounds_df.selectExpr(\"interview_id as r_i_id\", \"round_id\", \"score\")\n",
    "c_df.join(r_df, col(\"c_i_id\") == col(\"r_i_id\"), \"left\").filter(\n",
    "    col(\"years_of_exp\") >= 2\n",
    ").groupBy(col(\"c_id\")).agg(sum(col(\"score\")).alias(\"total_score\")).filter(\n",
    "    col(\"total_score\") > 15\n",
    ").selectExpr(\n",
    "    \"c_id as candidate_id\"\n",
    ").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e695ef5-c230-416a-a5df-bb48abfd99a8",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758686411656}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select candidate_id from Candidates c left join Rounds r\n",
    "on c.interview_id = r.interview_id\n",
    "where  c.years_of_exp >= 2\n",
    "group by candidate_id\n",
    "having (sum(score)>15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b9789b7-9548-4f3b-8904-b9df8bda91d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SQL logic\n",
    "query = \"\"\"\n",
    "SELECT c.candidate_id\n",
    "FROM Candidates c\n",
    "JOIN (\n",
    "    SELECT interview_id, SUM(score) AS total_score\n",
    "    FROM Rounds\n",
    "    GROUP BY interview_id\n",
    ") r ON c.interview_id = r.interview_id\n",
    "WHERE c.years_of_exp >= 2 AND r.total_score > 15\n",
    "\"\"\"\n",
    "\n",
    "result_df = spark.sql(query)\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6400570187503226,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2041_leetcode_medium",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
