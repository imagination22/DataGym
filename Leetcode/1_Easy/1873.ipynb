{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7c034ff-2797-4075-a183-113dfc147354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/*\n",
    "1873. Calculate Special Bonus\n",
    "Table: Employees\n",
    "\n",
    "+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| employee_id | int     |\n",
    "| name        | varchar |\n",
    "| salary      | int     |\n",
    "+-------------+---------+\n",
    "employee_id is the primary key (column with unique values) for this table.\n",
    "Each row of this table indicates the employee ID, employee name, and salary.\n",
    " \n",
    "\n",
    "Write a solution to calculate the bonus of each employee. The bonus of an employee is 100% of their salary if the ID of the employee is an odd number and the employee''s name does not start with the character 'M'. The bonus of an employee is 0 otherwise.\n",
    "\n",
    "Return the result table ordered by employee_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employees table:\n",
    "+-------------+---------+--------+\n",
    "| employee_id | name    | salary |\n",
    "+-------------+---------+--------+\n",
    "| 2           | Meir    | 3000   |\n",
    "| 3           | Michael | 3800   |\n",
    "| 7           | Addilyn | 7400   |\n",
    "| 8           | Juan    | 6100   |\n",
    "| 9           | Kannon  | 7700   |\n",
    "+-------------+---------+--------+\n",
    "Output: \n",
    "+-------------+-------+\n",
    "| employee_id | bonus |\n",
    "+-------------+-------+\n",
    "| 2           | 0     |\n",
    "| 3           | 0     |\n",
    "| 7           | 7400  |\n",
    "| 8           | 0     |\n",
    "| 9           | 7700  |\n",
    "+-------------+-------+\n",
    "Explanation: \n",
    "The employees with IDs 2 and 8 get 0 bonus because they have an even employee_id.\n",
    "The employee with ID 3 gets 0 bonus because their name starts with 'M'.\n",
    "The rest of the employees get a 100% bonus.*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e2c7f8f-f13d-49b3-bd8c-20d8f38327f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (2, \"Meir\", 3000),\n",
    "    (3, \"Michael\", 3800),\n",
    "    (7, \"Addilyn\", 7400),\n",
    "    (8, \"Juan\", 6100),\n",
    "    (9, \"Kannon\", 7700)\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Register as SQL view\n",
    "df.createOrReplaceTempView(\"Employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3464a980-cc21-460a-b213-e025fec39735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- SQL: Calculate Special Bonus\n",
    "SELECT \n",
    "    employee_id,\n",
    "    CASE \n",
    "        WHEN employee_id % 2 = 1 AND LEFT(name, 1) != 'M' THEN salary\n",
    "        ELSE 0\n",
    "    END AS bonus\n",
    "FROM Employees\n",
    "ORDER BY employee_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d246b3b-c917-469e-b9e3-77a8e8750f55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df_bonus = df.withColumn(\n",
    "    \"bonus\",\n",
    "    when((col(\"employee_id\") % 2 == 1) & (col(\"name\").substr(1, 1) != \"M\"), col(\"salary\")).otherwise(0)\n",
    ").select(\"employee_id\", \"bonus\").orderBy(\"employee_id\")\n",
    "\n",
    "df_bonus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab748ecb-3f5e-4e2c-bfff-a2e825850bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If you run this code **twice** in a Databricks notebook, hereâ€™s exactly what happens:\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **PySpark DataFrame Creation**\n",
    "Each time you run the cell:\n",
    "- A new DataFrame `df` is created with the same data and schema.\n",
    "- It doesnâ€™t overwrite or conflict with the previous `df` unless youâ€™ve reassigned or reused it elsewhere.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **SQL View Registration**\n",
    "The line:\n",
    "```python\n",
    "df.createOrReplaceTempView(\"Employees\")\n",
    "```\n",
    "means:\n",
    "- If a temp view named `\"Employees\"` already exists, it will be **replaced** with the new one.\n",
    "- So running it twice simply **refreshes** the view with the same data.\n",
    "- No error, no duplication, no side effectsâ€”just a clean overwrite.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Why This Is Useful\n",
    "- You can rerun setup cells anytime to reset your data state.\n",
    "- Itâ€™s safe and predictable, especially when iterating on logic or debugging.\n",
    "\n",
    "---\n",
    "\n",
    "If you ever want to simulate changes (e.g., update salary, add rows), you can modify the `data` list before rerunning. Want help building a reusable cell that lets you toggle between different test datasets?\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8983900498514582,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1873",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
