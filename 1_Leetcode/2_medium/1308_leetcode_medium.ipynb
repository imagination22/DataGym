{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "329840c6-99d3-4cf8-b51c-42ae4a2c0dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1308. Running Total for Different Genders\n",
    "### Table: Scores\n",
    "\n",
    "| Column Name   | Type    |\n",
    "|---------------|---------|\n",
    "| player_name   | varchar |\n",
    "| gender        | varchar |\n",
    "| day           | date    |\n",
    "| score_points  | int     |\n",
    "\n",
    "(gender, day) is the primary key for this table.  \n",
    "A competition is held between females team and males team.  \n",
    "Each row of this table indicates that a player_name and with gender has scored score_point in someday.  \n",
    "Gender is 'F' if the player is in females team and 'M' if the player is in males team.\n",
    "\n",
    "Write an SQL query to find the total score for each gender at each day.\n",
    "\n",
    "Order the result table by gender and day\n",
    "\n",
    "---\n",
    "\n",
    "### Scores table:\n",
    "\n",
    "| player_name | gender | day        | score_points |\n",
    "|-------------|--------|------------|--------------|\n",
    "| Aron        | F      | 2020-01-01 | 17           |\n",
    "| Alice       | F      | 2020-01-07 | 23           |\n",
    "| Bajrang     | M      | 2020-01-07 | 7            |\n",
    "| Khali       | M      | 2019-12-25 | 11           |\n",
    "| Slaman      | M      | 2019-12-30 | 13           |\n",
    "| Joe         | M      | 2019-12-31 | 3            |\n",
    "| Jose        | M      | 2019-12-18 | 2            |\n",
    "| Priya       | F      | 2019-12-31 | 23           |\n",
    "| Priyanka    | F      | 2019-12-30 | 17           |\n",
    "\n",
    "---\n",
    "\n",
    "### Result table:\n",
    "\n",
    "| gender | day        | total |\n",
    "|--------|------------|-------|\n",
    "| F      | 2019-12-30 | 17    |\n",
    "| F      | 2019-12-31 | 40    |\n",
    "| F      | 2020-01-01 | 57    |\n",
    "| F      | 2020-01-07 | 80    |\n",
    "| M      | 2019-12-18 | 2     |\n",
    "| M      | 2019-12-25 | 13    |\n",
    "| M      | 2019-12-30 | 26    |\n",
    "| M      | 2019-12-31 | 29    |\n",
    "| M      | 2020-01-07 | 36    |\n",
    "\n",
    "---\n",
    "\n",
    "**Explanation:**  \n",
    "For females team:  \n",
    "First day is 2019-12-30, Priyanka scored 17 points and the total score for the team is 17.  \n",
    "Second day is 2019-12-31, Priya scored 23 points and the total score for the team is 40.  \n",
    "Third day is 2020-01-01, Aron scored 17 points and the total score for the team is 57.  \n",
    "Fourth day is 2020-01-07, Alice scored 23 points and the total score for the team is 80.  \n",
    "\n",
    "For males team:  \n",
    "First day is 2019-12-18, Jose scored 2 points and the total score for the team is 2.  \n",
    "Second day is 2019-12-25, Khali scored 11 points and the total score for the team is 13.  \n",
    "Third day is 2019-12-30, Slaman scored 13 points and the total score for the team is 26.  \n",
    "Fourth day is 2019-12-31, Joe scored 3 points and the total score for the team is 29.  \n",
    "Fifth day is 2020-01-07, Bajrang scored 7 points and the total score for the team is 36.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337ecef8-aa80-4130-80c2-b428610d76e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"GenderScoreAggregation\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"day\", DateType(), True),\n",
    "    StructField(\"score_points\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "from datetime import datetime\n",
    "\n",
    "# Original data with date strings\n",
    "raw_data = [\n",
    "    (\"Aron\", \"F\", \"2020-01-01\", 17),\n",
    "    (\"Alice\", \"F\", \"2020-01-07\", 23),\n",
    "    (\"Bajrang\", \"M\", \"2020-01-07\", 7),\n",
    "    (\"Khali\", \"M\", \"2019-12-25\", 11),\n",
    "    (\"Slaman\", \"M\", \"2019-12-30\", 13),\n",
    "    (\"Joe\", \"M\", \"2019-12-31\", 3),\n",
    "    (\"Jose\", \"M\", \"2019-12-18\", 2),\n",
    "    (\"Priya\", \"F\", \"2019-12-31\", 23),\n",
    "    (\"Priyanka\", \"F\", \"2019-12-30\", 17)\n",
    "]\n",
    "\n",
    "# Convert date strings to datetime.date objects\n",
    "data = [(name, gender, datetime.strptime(day, \"%Y-%m-%d\").date(), score) for name, gender, day, score in raw_data]\n",
    "\n",
    "# Preview the result\n",
    "for row in data:\n",
    "    print(row)\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.createOrReplaceTempView(\"Scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79191fd-ab3b-4188-9c83-04f527514b45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "win_func = Window.partitionBy(col(\"gender\")).orderBy(col(\"day\").asc())\n",
    "c_sum = sum(col(\"score_points\")).over(win_func)\n",
    "df = df.withColumn(\"total\", c_sum).select(\"gender\", \"day\", \"total\").display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2469893a-27a3-45ad-b3e6-551da2bdeb5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select * from Scores;\n",
    "with cte as (\n",
    " Select sum(score_points)over(partition by gender order by day asc) as total, * from scores \n",
    ")\n",
    "select gender , Day , total from cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a490a615-181c-4eee-8cd1-1e4302db1977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SQL logic\n",
    "query = \"\"\"\n",
    "SELECT gender, day, SUM(score_points) AS total\n",
    "FROM Scores\n",
    "GROUP BY gender, day\n",
    "ORDER BY gender, day\n",
    "\"\"\"\n",
    "\n",
    "# Execute and display\n",
    "result = spark.sql(query)\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4954692329817630,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1308_leetcode_medium",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
