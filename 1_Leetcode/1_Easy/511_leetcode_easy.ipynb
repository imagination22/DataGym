{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11606cc7-c632-47d2-b09a-3bbdcc547c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß† Leetcode 511 ‚Äî Game Play Analysis I (Databricks Edition)\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Problem Statement\n",
    "\n",
    "### Table: Activity\n",
    "\n",
    "| Column Name  | Type    |\n",
    "|--------------|---------|\n",
    "| player_id    | int     |\n",
    "| device_id    | int     |\n",
    "| event_date   | date    |\n",
    "| games_played | int     |\n",
    "\n",
    "- `(player_id, event_date)` is the primary key.\n",
    "- This table shows the activity of players of some games.\n",
    "- Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objective\n",
    "\n",
    "Write a query to find the **first login date** for each player.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Example\n",
    "\n",
    "### Input\n",
    "\n",
    "**Activity Table**\n",
    "\n",
    "| player_id | device_id | event_date | games_played |\n",
    "|-----------|-----------|------------|--------------|\n",
    "| 1         | 2         | 2016-03-01 | 5            |\n",
    "| 1         | 2         | 2016-05-02 | 6            |\n",
    "| 2         | 3         | 2017-06-25 | 1            |\n",
    "| 3         | 1         | 2016-03-02 | 0            |\n",
    "| 3         | 4         | 2018-07-03 | 5            |\n",
    "\n",
    "### Output\n",
    "\n",
    "| player_id | first_login |\n",
    "|-----------|-------------|\n",
    "| 1         | 2016-03-01  |\n",
    "| 2         | 2017-06-25  |\n",
    "| 3         | 2016-03-02  |\n",
    "\n",
    "---\n",
    "\n",
    "## üß± PySpark DataFrame Creation\n",
    "\n",
    "```python\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Sample data\n",
    "activity_data = [\n",
    "    Row(player_id=1, device_id=2, event_date=\"2016-03-01\", games_played=5),\n",
    "    Row(player_id=1, device_id=2, event_date=\"2016-05-02\", games_played=6),\n",
    "    Row(player_id=2, device_id=3, event_date=\"2017-06-25\", games_played=1),\n",
    "    Row(player_id=3, device_id=1, event_date=\"2016-03-02\", games_played=0),\n",
    "    Row(player_id=3, device_id=4, event_date=\"2018-07-03\", games_played=5)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "activity_df = spark.createDataFrame(activity_data)\n",
    "\n",
    "# Register temp view\n",
    "activity_df.createOrReplaceTempView(\"Activity\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ SQL Solution\n",
    "\n",
    "```sql\n",
    "SELECT player_id, MIN(event_date) AS first_login\n",
    "FROM Activity\n",
    "GROUP BY player_id;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ PySpark Solution\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "result_df = activity_df.groupBy(\"player_id\") \\\n",
    "                       .agg(min(\"event_date\").alias(\"first_login\"))\n",
    "\n",
    "result_df.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üìò *This notebook is part of DataGym‚Äôs SQL-to-PySpark transition series. Want to build a reusable template for aggregation-based problems or player activity analysis? Let‚Äôs co-create it!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4032930b-390a-4e88-8d13-dfe436ab54e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.types import StringType, IntegerType , StructType , StructField , DateType\n",
    "from datetime import date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb82da84-816e-4583-85d4-a66d4bc6f54c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DateType\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "# 1Ô∏è‚É£ Sample Data\n",
    "data = [\n",
    "    (1, 2, date(2016, 3, 1), 5),\n",
    "    (1, 2, date(2016, 5, 2), 6),\n",
    "    (2, 3, date(2017, 6, 25), 1),\n",
    "    (3, 1, date(2016, 3, 2), 0),\n",
    "    (3, 4, date(2018, 7, 3), 5)\n",
    "]\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Schema Definition\n",
    "schema = StructType([\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"device_id\", IntegerType(), True),\n",
    "    StructField(\"event_date\", DateType(), True),\n",
    "    StructField(\"games_played\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# 3Ô∏è‚É£ Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# 4Ô∏è‚É£ Register Temp View\n",
    "df.createOrReplaceTempView(\"Activity\")\n",
    "\n",
    "# 5Ô∏è‚É£ SQL Query: First Login Date per Player\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT player_id, MIN(event_date) AS first_login\n",
    "    FROM Activity\n",
    "    GROUP BY player_id\n",
    "\"\"\")\n",
    "\n",
    "# 6Ô∏è‚É£ Show Result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eff0d38-f866-48fd-9677-af773c41558b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4d50a7-69b0-4df0-b359-9d766f26b011",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758347373103}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "v_window = Window.partitionBy(col(\"player_id\")).orderBy(col(\"event_date\").asc())\n",
    "v_row =row_number().over(v_window)\n",
    "df.withColumn(\"row\",v_row).filter(col(\"row\")==1).selectExpr(\"player_id as player_id \",\"event_date as first_login\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "511_leetcode_easy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
