{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64a4bad6-9675-4c24-b9b6-bc904e8c881d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1113. Reported Posts\n",
    "### Table: Actions\n",
    "\n",
    "| Column Name   | Type    |\n",
    "|---------------|---------|\n",
    "| user_id       | int     |\n",
    "| post_id       | int     |\n",
    "| action_date   | date    |\n",
    "| action        | enum    |\n",
    "| extra         | varchar |\n",
    "\n",
    "**Primary Key**: None â€” this table may contain duplicate rows.\n",
    "\n",
    "**Description**:\n",
    "The `Actions` table records user interactions with posts.  \n",
    "The `action` column is an ENUM type with values:  \n",
    "`('view', 'like', 'reaction', 'comment', 'report', 'share')`  \n",
    "The `extra` column contains optional metadata like report reasons or reaction types.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Business Logic:\n",
    "There is no primary key for this table, it may have duplicate rows.\n",
    "\n",
    "The action column is an ENUM type of ('view', 'like', 'reaction', 'comment', 'report', 'share').\n",
    "\n",
    "The extra column has optional information about the action such as a reason for report or a type of reaction. \n",
    "\n",
    "Write an SQL query that reports the number of posts reported yesterday for each report reason. Assume today is 2019-07-05.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Expected Output Format:\n",
    "\n",
    "#### Input:\n",
    "| user_id | post_id | action_date | action | extra  |\n",
    "|---------|---------|-------------|--------|--------|\n",
    "| 1       | 1       | 2019-07-01  | view   | null   |\n",
    "| 1       | 1       | 2019-07-01  | like   | null   |\n",
    "| 1       | 1       | 2019-07-01  | share  | null   |\n",
    "| 2       | 4       | 2019-07-04  | view   | null   |\n",
    "| 2       | 4       | 2019-07-04  | report | spam   |\n",
    "| 3       | 4       | 2019-07-04  | view   | null   |\n",
    "| 3       | 4       | 2019-07-04  | report | spam   |\n",
    "| 4       | 3       | 2019-07-02  | view   | null   |\n",
    "| 4       | 3       | 2019-07-02  | report | spam   |\n",
    "| 5       | 2       | 2019-07-04  | view   | null   |\n",
    "| 5       | 2       | 2019-07-04  | report | racism |\n",
    "| 5       | 5       | 2019-07-04  | view   | null   |\n",
    "| 5       | 5       | 2019-07-04  | report | racism |\n",
    "\n",
    "#### Output:\n",
    "| report_reason | report_count |\n",
    "|---------------|--------------|\n",
    "| spam          | 1            |\n",
    "| racism        | 2            |\n",
    "\n",
    "**Explanation**:  \n",
    "- `spam`: post_id 4 was reported â†’ count = 1  \n",
    "- `racism`: post_ids 2 and 5 were reported â†’ count = 2  \n",
    "- Only distinct post_ids are counted per reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd757196-e949-4508-a7cc-f3f94f81c1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Sample data with date as string\n",
    "data = [\n",
    "    (1, 1, \"2019-07-01\", \"view\", None),\n",
    "    (1, 1, \"2019-07-01\", \"like\", None),\n",
    "    (1, 1, \"2019-07-01\", \"share\", None),\n",
    "    (2, 4, \"2019-07-04\", \"view\", None),\n",
    "    (2, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
    "    (3, 4, \"2019-07-04\", \"view\", None),\n",
    "    (3, 4, \"2019-07-04\", \"report\", \"spam\"),\n",
    "    (4, 3, \"2019-07-02\", \"view\", None),\n",
    "    (4, 3, \"2019-07-02\", \"report\", \"spam\"),\n",
    "    (5, 2, \"2019-07-04\", \"view\", None),\n",
    "    (5, 2, \"2019-07-04\", \"report\", \"racism\"),\n",
    "    (5, 5, \"2019-07-04\", \"view\", None),\n",
    "    (5, 5, \"2019-07-04\", \"report\", \"racism\")\n",
    "]\n",
    "\n",
    "# Define schema with action_date as StringType first\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"post_id\", IntegerType(), True),\n",
    "    StructField(\"action_date\", StringType(), True),  # initially string\n",
    "    StructField(\"action\", StringType(), True),\n",
    "    StructField(\"extra\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df_raw = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Convert action_date to proper DateType\n",
    "df = df_raw.withColumn(\"action_date\", to_date(col(\"action_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Register Temp View\n",
    "df.createOrReplaceTempView(\"Actions\")\n",
    "\n",
    "# SQL logic to count distinct post_ids reported on 2019-07-04\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT extra AS report_reason,\n",
    "           COUNT(DISTINCT post_id) AS report_count\n",
    "    FROM Actions\n",
    "    WHERE action = 'report'\n",
    "      AND action_date = DATE('2019-07-04')\n",
    "    GROUP BY extra\n",
    "\"\"\")\n",
    "\n",
    "# Display result\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27c1aad6-6f38-417c-a5f5-67d45621d02d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.filter((col(\"action\") == \"report\") & (col(\"action_date\") == \"2019-07-04\"))\\\n",
    "    .groupBy(col(\"extra\"))\\\n",
    "        .agg(countDistinct(\"post_id\"))\\\n",
    "            .display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecf99ffc-8ab0-44d7-87f0-6911c50e4380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1113_leetcode_easy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
